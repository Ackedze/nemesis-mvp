# Аудит Nemesis MVP

## Обзор
- Проверены ключевые модули плагина (`src/code.ts`, `src/ui.html`), сборка (`build.js`, `scripts/`) и конфигурация зависимостей (`package.json`).
- Цель — описать текущие ограничения и области внимания, которые влияют на стабильность и поддержку сборок.

## Наблюдения
1. **GPT-запросы завязаны на локальный proxy.** Запрос всегда отправляется на `LLM_PROXY_ENDPOINT = http://localhost:3000/yandex-llm`, и `handleGptRequest` создаёт `fetch` к этому адресу без запасного варианта (`Nemesis-mvp/src/code.ts:95-1025`). Без запущенного прокси плагин мгновенно выдаёт ошибку, хотя манифест разрешает доступа к `https://llm.api.cloud.yandex.net`. Рекомендуется сделать `LLM_PROXY_ENDPOINT` конфигурируемым или добавить fallback на прямой API.
2. **Сбор справочников требует сети или заранее скачанного файла.** `scripts/prepareReferences.js` скачивает `JSONS-MVP/referenceSourcesMVP.json` с `ackedze.github.io` (линии `15-146`). Если соединение недоступно и локального cache-файла нет, скрипт бросает исключение, и `npm run build` падает, несмотря на то, что offline-режим (`NEMESIS_OFFLINE=1`) существует только для предсозданных файлов. Для локальной разработки важно держать актуальный JSON или расширить fallback.
3. **Нет автоматических тестов или линтеров.** В `package.json` есть только `build` и `watch` без `test`, `lint` или `type-check` (строки `1-12`). Это означает, что регрессии обнаруживаются только при ручной сборке/сканировании, а повторяемость ограничена одной командой `npm run build`.

## Рекомендации
- Рассмотреть добавление конфигурации для `LLM_PROXY_ENDPOINT` или возможность обходиться без локального прокси.
- Документировать процесс актуализации `JSONS-MVP/referenceSourcesMVP.json`, чтобы сборка могла работать автономно.
- Добавить хотя бы один автоматизированный скрипт (lint или типовая проверка), чтобы верифицировать изменения до сборки.
